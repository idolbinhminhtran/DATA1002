{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a352857e",
   "metadata": {},
   "source": [
    "# Premier League Data Integration and Cleaning\n",
    "## Merging 10 Years of Premier League Match Data (2015-2025)\n",
    "\n",
    "This notebook performs:\n",
    "1. Loading all 10 individual season CSV files\n",
    "2. Data quality checks for each season\n",
    "3. Data cleaning and standardization\n",
    "4. Integration into a single comprehensive dataset\n",
    "5. Export to processed data directory\n",
    "\n",
    "**Data Sources:** 10 CSV files covering Premier League seasons 2015-16 through 2024-25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721cec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and paths set up successfully!\n",
      "Raw data path: ..\\data\\raw\\PL_matches\n",
      "Processed data path: ..\\data\\processed\n",
      "Raw data path exists: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configure warnings to show specific types that might be useful for data cleaning\n",
    "warnings.filterwarnings('default', category=pd.errors.DtypeWarning)\n",
    "warnings.filterwarnings('default', category=pd.errors.ParserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Set up robust paths using pathlib\n",
    "RAW_DATA_PATH = Path(\"../data/raw/PL_matches/\")\n",
    "PROCESSED_DATA_PATH = Path(\"../data/processed/\")\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "PROCESSED_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Libraries imported and paths set up successfully!\")\n",
    "print(f\"Raw data path: {RAW_DATA_PATH}\")\n",
    "print(f\"Processed data path: {PROCESSED_DATA_PATH}\")\n",
    "print(f\"Raw data path exists: {RAW_DATA_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606db75",
   "metadata": {},
   "source": [
    "## 1. Discovery: Load and Inspect Individual Season Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196853b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 season files:\n",
      "  - 2015-2016\n",
      "  - 2016-2017\n",
      "  - 2017-2018\n",
      "  - 2018-2019\n",
      "  - 2019-2020\n",
      "  - 2020-2021\n",
      "  - 2021-2022\n",
      "  - 2022-2023\n",
      "  - 2023-2024\n",
      "  - 2024-2025\n"
     ]
    }
   ],
   "source": [
    "# Get all CSV files in the PL_matches directory using pathlib\n",
    "csv_files = list(RAW_DATA_PATH.glob(\"*.csv\"))\n",
    "csv_files = [f for f in csv_files if not f.name.endswith(\"PLdata-10-years.csv\")]  # Exclude existing merged file\n",
    "csv_files.sort()\n",
    "\n",
    "print(f\"Found {len(csv_files)} season files:\")\n",
    "for file in csv_files:\n",
    "    season = file.stem  # Use pathlib's stem property instead of os.path.basename\n",
    "    print(f\"  - {season}\")\n",
    "\n",
    "# Dictionary to store season dataframes\n",
    "season_dataframes = {}\n",
    "season_info = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82feed79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 2015-2016: 380 rows, 65 columns\n",
      "✓ Loaded 2016-2017: 380 rows, 65 columns\n",
      "✓ Loaded 2017-2018: 380 rows, 65 columns\n",
      "✓ Loaded 2018-2019: 380 rows, 62 columns\n",
      "✓ Loaded 2019-2020: 380 rows, 106 columns\n",
      "✓ Loaded 2020-2021: 380 rows, 106 columns\n",
      "✓ Loaded 2021-2022: 380 rows, 106 columns\n",
      "✓ Loaded 2022-2023: 380 rows, 106 columns\n",
      "✓ Loaded 2023-2024: 380 rows, 106 columns\n",
      "✓ Loaded 2024-2025: 380 rows, 120 columns\n",
      "\n",
      "============================================================\n",
      "SEASON SUMMARY:\n",
      "   Season  Rows  Columns               Date_Range  Missing_Values  Unique_Home_Teams  Unique_Away_Teams\n",
      "2015-2016   380       65 01/03/2016 to 31/10/2015               3                 20                 20\n",
      "2016-2017   380       65     01/01/17 to 31/12/16               0                 20                 20\n",
      "2017-2018   380       65 01/01/2018 to 31/12/2017               0                 20                 20\n",
      "2018-2019   380       62 01/01/2019 to 31/03/2019               0                 20                 20\n",
      "2019-2020   380      106 01/01/2020 to 31/08/2019               0                 20                 20\n",
      "2020-2021   380      106 01/01/2021 to 31/10/2020               0                 20                 20\n",
      "2021-2022   380      106 01/01/2022 to 31/10/2021              13                 20                 20\n",
      "2022-2023   380      106 01/01/2023 to 31/12/2022               4                 20                 20\n",
      "2023-2024   380      106 01/01/2024 to 31/12/2023            1166                 20                 20\n",
      "2024-2025   380      120 01/01/2025 to 31/08/2024            1440                 20                 20\n",
      "\n",
      "============================================================\n",
      "SEASON SUMMARY:\n",
      "   Season  Rows  Columns               Date_Range  Missing_Values  Unique_Home_Teams  Unique_Away_Teams\n",
      "2015-2016   380       65 01/03/2016 to 31/10/2015               3                 20                 20\n",
      "2016-2017   380       65     01/01/17 to 31/12/16               0                 20                 20\n",
      "2017-2018   380       65 01/01/2018 to 31/12/2017               0                 20                 20\n",
      "2018-2019   380       62 01/01/2019 to 31/03/2019               0                 20                 20\n",
      "2019-2020   380      106 01/01/2020 to 31/08/2019               0                 20                 20\n",
      "2020-2021   380      106 01/01/2021 to 31/10/2020               0                 20                 20\n",
      "2021-2022   380      106 01/01/2022 to 31/10/2021              13                 20                 20\n",
      "2022-2023   380      106 01/01/2023 to 31/12/2022               4                 20                 20\n",
      "2023-2024   380      106 01/01/2024 to 31/12/2023            1166                 20                 20\n",
      "2024-2025   380      120 01/01/2025 to 31/08/2024            1440                 20                 20\n"
     ]
    }
   ],
   "source": [
    "# Load each season file and gather basic information\n",
    "for file_path in csv_files:\n",
    "    season = file_path.stem\n",
    "    \n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        season_dataframes[season] = df\n",
    "        \n",
    "        # Gather basic information\n",
    "        info = {\n",
    "            'Season': season,\n",
    "            'Rows': len(df),\n",
    "            'Columns': len(df.columns),\n",
    "            'Date_Range': f\"{df['Date'].min()} to {df['Date'].max()}\" if 'Date' in df.columns else 'No Date column',\n",
    "            'Missing_Values': df.isnull().sum().sum(),\n",
    "            'Unique_Home_Teams': df['HomeTeam'].nunique() if 'HomeTeam' in df.columns else 'No HomeTeam column',\n",
    "            'Unique_Away_Teams': df['AwayTeam'].nunique() if 'AwayTeam' in df.columns else 'No AwayTeam column'\n",
    "        }\n",
    "        season_info.append(info)\n",
    "        \n",
    "        print(f\"✓ Loaded {season}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading {season}: {str(e)}\")\n",
    "\n",
    "# Create summary dataframe\n",
    "season_summary = pd.DataFrame(season_info)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SEASON SUMMARY:\")\n",
    "print(season_summary.to_string(index=False))\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SEASON SUMMARY:\")\n",
    "print(season_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a6626",
   "metadata": {},
   "source": [
    "## 2. Data Quality Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672d19ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMN CONSISTENCY CHECK:\n",
      "==================================================\n",
      "Total unique columns across all seasons: 153\n",
      "\n",
      "'1XBA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'1XBCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'1XBCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'1XBCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'1XBD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'1XBH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'AHCh' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AHh' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'Avg<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'Avg>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgC<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgC>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgCAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgCAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'AvgH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365AHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365AHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365C<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365C>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365CA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365CAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365CAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365CD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'B365CH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'BFA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFE<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFE>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFEA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFEAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFEAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFEC<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFEC>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFECA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFECAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFECAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFECD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFECH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFED' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFEH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BFH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "\n",
      "'BWCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'BWCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'BWCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'Bb1X2' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAH' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAHh' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAv<2.5' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAv>2.5' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAvA' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAvAHA' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAvAHH' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAvD' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbAvH' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbMx<2.5' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbMx>2.5' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbMxA' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbMxAHA' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbMxAHH' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbMxD' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbMxH' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'BbOU' missing in: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'IWA' missing in: ['2024-2025']\n",
      "\n",
      "'IWCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2024-2025']\n",
      "\n",
      "'IWCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2024-2025']\n",
      "\n",
      "'IWCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2024-2025']\n",
      "\n",
      "'IWD' missing in: ['2024-2025']\n",
      "\n",
      "'IWH' missing in: ['2024-2025']\n",
      "\n",
      "'LBA' missing in: ['2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'LBD' missing in: ['2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'LBH' missing in: ['2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "\n",
      "'Max<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'Max>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxC<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxC>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxCAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxCAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'MaxH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'P<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'P>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'PAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'PAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'PC<2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'PC>2.5' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'PCAHA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'PCAHH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'Time' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'VCA' missing in: ['2024-2025']\n",
      "\n",
      "'VCCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2024-2025']\n",
      "\n",
      "'VCCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2024-2025']\n",
      "\n",
      "'VCCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2024-2025']\n",
      "\n",
      "'VCD' missing in: ['2024-2025']\n",
      "\n",
      "'VCH' missing in: ['2024-2025']\n",
      "\n",
      "'WHCA' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'WHCD' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "'WHCH' missing in: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "\n",
      "⚠ Found 115 inconsistent columns\n"
     ]
    }
   ],
   "source": [
    "# Check column consistency across seasons\n",
    "print(\"COLUMN CONSISTENCY CHECK:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get all unique columns across all seasons\n",
    "all_columns = set()\n",
    "for season, df in season_dataframes.items():\n",
    "    all_columns.update(df.columns)\n",
    "\n",
    "all_columns = sorted(list(all_columns))\n",
    "print(f\"Total unique columns across all seasons: {len(all_columns)}\")\n",
    "\n",
    "# Check which columns are present in each season\n",
    "column_presence = {}\n",
    "for col in all_columns:\n",
    "    column_presence[col] = []\n",
    "    for season in sorted(season_dataframes.keys()):\n",
    "        column_presence[col].append(col in season_dataframes[season].columns)\n",
    "\n",
    "# Display columns that are not present in all seasons\n",
    "inconsistent_columns = []\n",
    "for col, presence in column_presence.items():\n",
    "    if not all(presence):\n",
    "        inconsistent_columns.append(col)\n",
    "        seasons_with_col = [season for i, season in enumerate(sorted(season_dataframes.keys())) if presence[i]]\n",
    "        seasons_without_col = [season for i, season in enumerate(sorted(season_dataframes.keys())) if not presence[i]]\n",
    "        print(f\"\\n'{col}' missing in: {seasons_without_col}\")\n",
    "\n",
    "if not inconsistent_columns:\n",
    "    print(\"✓ All columns are consistent across seasons!\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Found {len(inconsistent_columns)} inconsistent columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ebf410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA QUALITY REPORT: 2015-2016\n",
      "----------------------------------------\n",
      "Shape: (380, 65)\n",
      "Memory usage: 0.19 MB\n",
      "\n",
      "Missing values:\n",
      "  BWH: 1 (0.3%)\n",
      "  BWD: 1 (0.3%)\n",
      "  BWA: 1 (0.3%)\n",
      "\n",
      "Data types:\n",
      "  float64: 39 columns\n",
      "  int64: 19 columns\n",
      "  object: 7 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2016-2017\n",
      "----------------------------------------\n",
      "Shape: (380, 65)\n",
      "Memory usage: 0.19 MB\n",
      "\n",
      "✓ No missing values\n",
      "\n",
      "Data types:\n",
      "  float64: 39 columns\n",
      "  int64: 19 columns\n",
      "  object: 7 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "⚠ Date format issues detected\n",
      "\n",
      "DATA QUALITY REPORT: 2017-2018\n",
      "----------------------------------------\n",
      "Shape: (380, 65)\n",
      "Memory usage: 0.19 MB\n",
      "\n",
      "✓ No missing values\n",
      "\n",
      "Data types:\n",
      "  float64: 39 columns\n",
      "  int64: 19 columns\n",
      "  object: 7 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2018-2019\n",
      "----------------------------------------\n",
      "Shape: (380, 62)\n",
      "Memory usage: 0.18 MB\n",
      "\n",
      "✓ No missing values\n",
      "\n",
      "Data types:\n",
      "  float64: 36 columns\n",
      "  int64: 19 columns\n",
      "  object: 7 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2019-2020\n",
      "----------------------------------------\n",
      "Shape: (380, 106)\n",
      "Memory usage: 0.31 MB\n",
      "\n",
      "✓ No missing values\n",
      "\n",
      "Data types:\n",
      "  float64: 82 columns\n",
      "  int64: 16 columns\n",
      "  object: 8 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2020-2021\n",
      "----------------------------------------\n",
      "Shape: (380, 106)\n",
      "Memory usage: 0.31 MB\n",
      "\n",
      "✓ No missing values\n",
      "\n",
      "Data types:\n",
      "  float64: 82 columns\n",
      "  int64: 16 columns\n",
      "  object: 8 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2021-2022\n",
      "----------------------------------------\n",
      "Shape: (380, 106)\n",
      "Memory usage: 0.31 MB\n",
      "\n",
      "Missing values:\n",
      "  B365>2.5: 1 (0.3%)\n",
      "  B365<2.5: 1 (0.3%)\n",
      "  IWCH: 3 (0.8%)\n",
      "  IWCD: 3 (0.8%)\n",
      "  IWCA: 3 (0.8%)\n",
      "  B365CAHH: 1 (0.3%)\n",
      "  B365CAHA: 1 (0.3%)\n",
      "\n",
      "Data types:\n",
      "  float64: 82 columns\n",
      "  int64: 16 columns\n",
      "  object: 8 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2022-2023\n",
      "----------------------------------------\n",
      "Shape: (380, 106)\n",
      "Memory usage: 0.31 MB\n",
      "\n",
      "Missing values:\n",
      "  P>2.5: 1 (0.3%)\n",
      "  P<2.5: 1 (0.3%)\n",
      "  PC>2.5: 1 (0.3%)\n",
      "  PC<2.5: 1 (0.3%)\n",
      "\n",
      "Data types:\n",
      "  float64: 82 columns\n",
      "  int64: 16 columns\n",
      "  object: 8 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2023-2024\n",
      "----------------------------------------\n",
      "Shape: (380, 106)\n",
      "Memory usage: 0.31 MB\n",
      "\n",
      "Missing values:\n",
      "  BWH: 2 (0.5%)\n",
      "  BWD: 2 (0.5%)\n",
      "  BWA: 2 (0.5%)\n",
      "  IWH: 182 (47.9%)\n",
      "  IWD: 182 (47.9%)\n",
      "  IWA: 182 (47.9%)\n",
      "  P>2.5: 8 (2.1%)\n",
      "  P<2.5: 8 (2.1%)\n",
      "  BWCH: 12 (3.2%)\n",
      "  BWCD: 12 (3.2%)\n",
      "  BWCA: 12 (3.2%)\n",
      "  IWCH: 182 (47.9%)\n",
      "  IWCD: 182 (47.9%)\n",
      "  IWCA: 182 (47.9%)\n",
      "  PC>2.5: 7 (1.8%)\n",
      "  PC<2.5: 7 (1.8%)\n",
      "  MaxCAHH: 1 (0.3%)\n",
      "  MaxCAHA: 1 (0.3%)\n",
      "\n",
      "Data types:\n",
      "  float64: 82 columns\n",
      "  int64: 16 columns\n",
      "  object: 8 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n",
      "\n",
      "DATA QUALITY REPORT: 2024-2025\n",
      "----------------------------------------\n",
      "Shape: (380, 120)\n",
      "Memory usage: 0.35 MB\n",
      "\n",
      "Missing values:\n",
      "  BWH: 141 (37.1%)\n",
      "  BWD: 141 (37.1%)\n",
      "  BWA: 141 (37.1%)\n",
      "  BFH: 1 (0.3%)\n",
      "  BFD: 1 (0.3%)\n",
      "  BFA: 1 (0.3%)\n",
      "  WHH: 91 (23.9%)\n",
      "  WHD: 91 (23.9%)\n",
      "  WHA: 91 (23.9%)\n",
      "  1XBH: 9 (2.4%)\n",
      "  1XBD: 9 (2.4%)\n",
      "  1XBA: 9 (2.4%)\n",
      "  P>2.5: 3 (0.8%)\n",
      "  P<2.5: 3 (0.8%)\n",
      "  BFE>2.5: 3 (0.8%)\n",
      "  BFE<2.5: 3 (0.8%)\n",
      "  BWCH: 141 (37.1%)\n",
      "  BWCD: 141 (37.1%)\n",
      "  BWCA: 141 (37.1%)\n",
      "  WHCH: 91 (23.9%)\n",
      "  WHCD: 91 (23.9%)\n",
      "  WHCA: 91 (23.9%)\n",
      "  PC>2.5: 3 (0.8%)\n",
      "  PC<2.5: 3 (0.8%)\n",
      "\n",
      "Data types:\n",
      "  float64: 96 columns\n",
      "  int64: 16 columns\n",
      "  object: 8 columns\n",
      "\n",
      "✓ No duplicate rows\n",
      "✓ Date format is consistent\n"
     ]
    }
   ],
   "source": [
    "# Detailed data quality check for each season\n",
    "def check_season_quality(df, season_name):\n",
    "    \"\"\"Perform comprehensive data quality check for a season\"\"\"\n",
    "    print(f\"\\nDATA QUALITY REPORT: {season_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(\"\\nMissing values:\")\n",
    "        missing_cols = missing[missing > 0]\n",
    "        for col, count in missing_cols.items():\n",
    "            print(f\"  {col}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n✓ No missing values\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"\\nData types:\")\n",
    "    dtype_counts = df.dtypes.value_counts()\n",
    "    for dtype, count in dtype_counts.items():\n",
    "        print(f\"  {dtype}: {count} columns\")\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"\\n⚠ Duplicate rows: {duplicates}\")\n",
    "    else:\n",
    "        print(f\"\\n✓ No duplicate rows\")\n",
    "    \n",
    "    # Date format check (if Date column exists)\n",
    "    if 'Date' in df.columns:\n",
    "        try:\n",
    "            # Try to parse dates\n",
    "            pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "            print(f\"✓ Date format is consistent\")\n",
    "        except:\n",
    "            print(f\"⚠ Date format issues detected\")\n",
    "    \n",
    "    return missing\n",
    "\n",
    "# Check quality for each season\n",
    "quality_issues = {}\n",
    "for season, df in season_dataframes.items():\n",
    "    quality_issues[season] = check_season_quality(df, season)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed97b7b",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eef29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning 2015-2016...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Missing values: 3 → 3\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2016-2017...\n",
      "  ✓ Date column converted (flexible parsing)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2017-2018...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2018-2019...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2019-2020...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2020-2021...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2021-2022...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Missing values: 13 → 13\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2022-2023...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Missing values: 4 → 4\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2023-2024...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Missing values: 1166 → 1166\n",
      "  ✓ Data types standardized\n",
      "Cleaning 2024-2025...\n",
      "  ✓ Date column converted (DD/MM/YYYY format)\n",
      "  ✓ Team names standardized\n",
      "  ✓ Season column added\n",
      "  ✓ Missing values: 1440 → 1440\n",
      "  ✓ Data types standardized\n",
      "\n",
      "==================================================\n",
      "DATA CLEANING COMPLETED!\n",
      "Cleaned 10 seasons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tuank\\AppData\\Local\\Temp\\ipykernel_27884\\460934252.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_clean['Date'] = pd.to_datetime(df_clean['Date'], dayfirst=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Define data cleaning functions\n",
    "def standardize_team_names(df):\n",
    "    \"\"\"Standardize team names across all seasons\"\"\"\n",
    "    # Common team name variations and their standard forms\n",
    "    team_name_mapping = {\n",
    "        'Man United': 'Manchester United',\n",
    "        'Man City': 'Manchester City', \n",
    "        'Spurs': 'Tottenham',\n",
    "        'Leicester': 'Leicester City',\n",
    "        'Wolves': 'Wolverhampton Wanderers',\n",
    "        'Brighton': 'Brighton & Hove Albion',\n",
    "        'West Brom': 'West Bromwich Albion',\n",
    "        'Stoke': 'Stoke City',\n",
    "        'Swansea': 'Swansea City',\n",
    "        'Hull': 'Hull City',\n",
    "        'Cardiff': 'Cardiff City',\n",
    "        'Norwich': 'Norwich City',\n",
    "        'Sheffield United': 'Sheffield Utd',\n",
    "        'Newcastle': 'Newcastle United',\n",
    "        'West Ham': 'West Ham United'\n",
    "    }\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Apply mapping to both HomeTeam and AwayTeam columns\n",
    "    if 'HomeTeam' in df_clean.columns:\n",
    "        df_clean['HomeTeam'] = df_clean['HomeTeam'].replace(team_name_mapping)\n",
    "    if 'AwayTeam' in df_clean.columns:\n",
    "        df_clean['AwayTeam'] = df_clean['AwayTeam'].replace(team_name_mapping)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_season_data(df, season_name):\n",
    "    \"\"\"Clean and standardize a single season's data\"\"\"\n",
    "    print(f\"Cleaning {season_name}...\")\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Convert Date column to datetime with flexible parsing\n",
    "    if 'Date' in df_clean.columns:\n",
    "        try:\n",
    "            # Try the most common format first\n",
    "            df_clean['Date'] = pd.to_datetime(df_clean['Date'], format='%d/%m/%Y')\n",
    "            print(f\"  ✓ Date column converted (DD/MM/YYYY format)\")\n",
    "        except ValueError:\n",
    "            try:\n",
    "                # Try flexible parsing with dayfirst=True for UK format\n",
    "                df_clean['Date'] = pd.to_datetime(df_clean['Date'], dayfirst=True, errors='coerce')\n",
    "                # Drop any rows where date conversion failed\n",
    "                invalid_dates = df_clean['Date'].isnull().sum()\n",
    "                if invalid_dates > 0:\n",
    "                    print(f\"  ⚠ Dropping {invalid_dates} rows with invalid dates\")\n",
    "                    df_clean = df_clean.dropna(subset=['Date'])\n",
    "                print(f\"  ✓ Date column converted (flexible parsing)\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠ Could not convert Date column: {e}\")\n",
    "    \n",
    "    # 2. Standardize team names\n",
    "    df_clean = standardize_team_names(df_clean)\n",
    "    print(f\"  ✓ Team names standardized\")\n",
    "    \n",
    "    # 3. Add season column\n",
    "    df_clean['Season'] = season_name\n",
    "    print(f\"  ✓ Season column added\")\n",
    "    \n",
    "    # 4. Handle missing values in numeric columns\n",
    "    numeric_columns = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    missing_before = df_clean[numeric_columns].isnull().sum().sum()\n",
    "    \n",
    "    if missing_before > 0:\n",
    "        # Fill missing values with 0 for match statistics (reasonable assumption)\n",
    "        stats_columns = [col for col in numeric_columns if col in ['HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR']]\n",
    "        if stats_columns:\n",
    "            df_clean[stats_columns] = df_clean[stats_columns].fillna(0)\n",
    "        \n",
    "        missing_after = df_clean[numeric_columns].isnull().sum().sum()\n",
    "        print(f\"  ✓ Missing values: {missing_before} → {missing_after}\")\n",
    "    \n",
    "    # 5. Ensure proper data types\n",
    "    # Goals should be integers\n",
    "    goal_columns = ['FTHG', 'FTAG', 'HTHG', 'HTAG']\n",
    "    for col in goal_columns:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    print(f\"  ✓ Data types standardized\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean all season data\n",
    "cleaned_dataframes = {}\n",
    "for season, df in season_dataframes.items():\n",
    "    cleaned_dataframes[season] = clean_season_data(df, season)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"DATA CLEANING COMPLETED!\")\n",
    "print(f\"Cleaned {len(cleaned_dataframes)} seasons\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a3c7e",
   "metadata": {},
   "source": [
    "## 4. Data Integration and Merging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888a08c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns across all seasons (39):\n",
      "['AC', 'AF', 'AR', 'AS', 'AST', 'AY', 'AwayTeam', 'B365A', 'B365D', 'B365H', 'BWA', 'BWD', 'BWH', 'Date', 'Div', 'FTAG', 'FTHG', 'FTR', 'HC', 'HF', 'HR', 'HS', 'HST', 'HTAG', 'HTHG', 'HTR', 'HY', 'HomeTeam', 'PSA', 'PSCA', 'PSCD', 'PSCH', 'PSD', 'PSH', 'Referee', 'Season', 'WHA', 'WHD', 'WHH']\n",
      "\n",
      "Season-specific columns:\n",
      "Found 115 season-specific columns:\n",
      "  1XBA: ['2024-2025']\n",
      "  1XBCA: ['2024-2025']\n",
      "  1XBCD: ['2024-2025']\n",
      "  1XBCH: ['2024-2025']\n",
      "  1XBD: ['2024-2025']\n",
      "  1XBH: ['2024-2025']\n",
      "  AHCh: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AHh: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  Avg<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  Avg>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgAHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgAHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgC<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgC>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgCA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgCAHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgCAHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgCD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgCH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  AvgH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365AHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365AHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365C<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365C>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365CA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365CAHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365CAHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365CD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  B365CH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  BFA: ['2024-2025']\n",
      "  BFCA: ['2024-2025']\n",
      "  BFCD: ['2024-2025']\n",
      "  BFCH: ['2024-2025']\n",
      "  BFD: ['2024-2025']\n",
      "  BFE<2.5: ['2024-2025']\n",
      "  BFE>2.5: ['2024-2025']\n",
      "  BFEA: ['2024-2025']\n",
      "  BFEAHA: ['2024-2025']\n",
      "  BFEAHH: ['2024-2025']\n",
      "  BFEC<2.5: ['2024-2025']\n",
      "  BFEC>2.5: ['2024-2025']\n",
      "  BFECA: ['2024-2025']\n",
      "  BFECAHA: ['2024-2025']\n",
      "  BFECAHH: ['2024-2025']\n",
      "  BFECD: ['2024-2025']\n",
      "  BFECH: ['2024-2025']\n",
      "  BFED: ['2024-2025']\n",
      "  BFEH: ['2024-2025']\n",
      "  BFH: ['2024-2025']\n",
      "  BWCA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  BWCD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  BWCH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  Bb1X2: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAH: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAHh: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAv<2.5: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAv>2.5: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAvA: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAvAHA: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAvAHH: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAvD: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbAvH: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbMx<2.5: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbMx>2.5: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbMxA: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbMxAHA: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbMxAHH: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbMxD: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbMxH: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  BbOU: ['2015-2016', '2016-2017', '2017-2018', '2018-2019']\n",
      "  IWA: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  IWCA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  IWCD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  IWCH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  IWD: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  IWH: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  LBA: ['2015-2016', '2016-2017', '2017-2018']\n",
      "  LBD: ['2015-2016', '2016-2017', '2017-2018']\n",
      "  LBH: ['2015-2016', '2016-2017', '2017-2018']\n",
      "  Max<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  Max>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxAHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxAHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxC<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxC>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxCA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxCAHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxCAHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxCD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxCH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  MaxH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  P<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  P>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  PAHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  PAHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  PC<2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  PC>2.5: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  PCAHA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  PCAHH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  Time: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  VCA: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  VCCA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  VCCD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  VCCH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  VCD: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  VCH: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024']\n",
      "  WHCA: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  WHCD: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  WHCH: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n"
     ]
    }
   ],
   "source": [
    "# Identify common columns across all seasons\n",
    "common_columns = None\n",
    "for season, df in cleaned_dataframes.items():\n",
    "    if common_columns is None:\n",
    "        common_columns = set(df.columns)\n",
    "    else:\n",
    "        common_columns = common_columns.intersection(set(df.columns))\n",
    "\n",
    "common_columns = sorted(list(common_columns))\n",
    "print(f\"Common columns across all seasons ({len(common_columns)}):\")\n",
    "print(common_columns)\n",
    "\n",
    "# Check for any season-specific columns\n",
    "print(f\"\\nSeason-specific columns:\")\n",
    "all_columns_clean = set()\n",
    "for season, df in cleaned_dataframes.items():\n",
    "    all_columns_clean.update(df.columns)\n",
    "\n",
    "season_specific = all_columns_clean - set(common_columns)\n",
    "if season_specific:\n",
    "    print(f\"Found {len(season_specific)} season-specific columns:\")\n",
    "    for col in sorted(season_specific):\n",
    "        seasons_with_col = []\n",
    "        for season, df in cleaned_dataframes.items():\n",
    "            if col in df.columns:\n",
    "                seasons_with_col.append(season)\n",
    "        print(f\"  {col}: {seasons_with_col}\")\n",
    "else:\n",
    "    print(\"No season-specific columns found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51285a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging all seasons...\n",
      "  Added 2015-2016: 380 rows\n",
      "  Added 2016-2017: 380 rows\n",
      "  Added 2017-2018: 380 rows\n",
      "  Added 2018-2019: 380 rows\n",
      "  Added 2019-2020: 380 rows\n",
      "  Added 2020-2021: 380 rows\n",
      "  Added 2021-2022: 380 rows\n",
      "  Added 2022-2023: 380 rows\n",
      "  Added 2023-2024: 380 rows\n",
      "  Added 2024-2025: 380 rows\n",
      "\n",
      "==================================================\n",
      "MERGE COMPLETED!\n",
      "Final merged dataset:\n",
      "  Shape: (3800, 39)\n",
      "  Date range: 2015-08-08 00:00:00 to 2025-05-25 00:00:00\n",
      "  Seasons: ['2015-2016', '2016-2017', '2017-2018', '2018-2019', '2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  Unique home teams: 34\n",
      "  Unique away teams: 34\n",
      "\n",
      "First 5 rows of merged dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AF</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>AST</th>\n",
       "      <th>AY</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>B365A</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365H</th>\n",
       "      <th>...</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSD</th>\n",
       "      <th>PSH</th>\n",
       "      <th>Referee</th>\n",
       "      <th>Season</th>\n",
       "      <th>WHA</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.70</td>\n",
       "      <td>3.88</td>\n",
       "      <td>1.82</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.95</td>\n",
       "      <td>M Clattenburg</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>Swansea City</td>\n",
       "      <td>11.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>5.04</td>\n",
       "      <td>1.37</td>\n",
       "      <td>4.92</td>\n",
       "      <td>1.39</td>\n",
       "      <td>M Oliver</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Watford</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>5.44</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.70</td>\n",
       "      <td>M Jones</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.95</td>\n",
       "      <td>...</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1.79</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1.99</td>\n",
       "      <td>L Mason</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>...</td>\n",
       "      <td>6.04</td>\n",
       "      <td>4.07</td>\n",
       "      <td>1.64</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1.65</td>\n",
       "      <td>J Moss</td>\n",
       "      <td>2015-2016</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AC  AF  AR  AS  AST  AY      AwayTeam  B365A  B365D  B365H  ...   PSCA  \\\n",
       "0   3  13   0   7    3   4   Aston Villa   4.00    3.6   2.00  ...   4.70   \n",
       "1   8  16   0  18   10   3  Swansea City  11.00    5.0   1.36  ...  10.88   \n",
       "2   2  13   0  11    5   2       Watford   5.50    3.9   1.70  ...   5.44   \n",
       "3   3  17   0  10    5   4    Sunderland   4.33    3.5   1.95  ...   5.10   \n",
       "4   2  12   0   9    4   3     Tottenham   6.00    4.0   1.65  ...   6.04   \n",
       "\n",
       "   PSCD  PSCH   PSD   PSH        Referee     Season   WHA  WHD   WHH  \n",
       "0  3.88  1.82  3.65  1.95  M Clattenburg  2015-2016   4.0  3.5  1.91  \n",
       "1  5.04  1.37  4.92  1.39       M Oliver  2015-2016  10.0  4.0  1.40  \n",
       "2  3.76  1.75  3.95  1.70        M Jones  2015-2016   5.0  3.5  1.73  \n",
       "3  3.74  1.79  3.48  1.99        L Mason  2015-2016   2.7  3.1  2.00  \n",
       "4  4.07  1.64  4.09  1.65         J Moss  2015-2016   6.0  3.6  1.62  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all seasons into a single dataframe\n",
    "print(\"Merging all seasons...\")\n",
    "\n",
    "# Use only common columns for consistency\n",
    "merged_dataframes = []\n",
    "for season, df in cleaned_dataframes.items():\n",
    "    # Select only common columns\n",
    "    df_subset = df[common_columns].copy()\n",
    "    merged_dataframes.append(df_subset)\n",
    "    print(f\"  Added {season}: {len(df_subset)} rows\")\n",
    "\n",
    "# Concatenate all dataframes\n",
    "pl_merged = pd.concat(merged_dataframes, ignore_index=True)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"MERGE COMPLETED!\")\n",
    "print(f\"Final merged dataset:\")\n",
    "print(f\"  Shape: {pl_merged.shape}\")\n",
    "print(f\"  Date range: {pl_merged['Date'].min()} to {pl_merged['Date'].max()}\")\n",
    "print(f\"  Seasons: {sorted(pl_merged['Season'].unique())}\")\n",
    "print(f\"  Unique home teams: {pl_merged['HomeTeam'].nunique()}\")\n",
    "print(f\"  Unique away teams: {pl_merged['AwayTeam'].nunique()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nFirst 5 rows of merged dataset:\")\n",
    "pl_merged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36809d74",
   "metadata": {},
   "source": [
    "## 5. Final Data Validation and Enhancement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755a0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL VALIDATION:\n",
      "========================================\n",
      "⚠ Warning: 705 missing values remain\n",
      "BWA    144\n",
      "BWD    144\n",
      "BWH    144\n",
      "WHA     91\n",
      "WHD     91\n",
      "WHH     91\n",
      "dtype: int64\n",
      "✓ No duplicate matches\n",
      "\n",
      "Date range validation:\n",
      "  2015-2016: 2015-08-08 to 2016-05-17 (380 matches)\n",
      "  2016-2017: 2016-08-13 to 2017-05-21 (380 matches)\n",
      "  2017-2018: 2017-08-11 to 2018-05-13 (380 matches)\n",
      "  2018-2019: 2018-08-10 to 2019-05-12 (380 matches)\n",
      "  2019-2020: 2019-08-09 to 2020-07-26 (380 matches)\n",
      "  2020-2021: 2020-09-12 to 2021-05-23 (380 matches)\n",
      "  2021-2022: 2021-08-13 to 2022-05-22 (380 matches)\n",
      "  2022-2023: 2022-08-05 to 2023-05-28 (380 matches)\n",
      "  2023-2024: 2023-08-11 to 2024-05-19 (380 matches)\n",
      "  2024-2025: 2024-08-16 to 2025-05-25 (380 matches)\n",
      "\n",
      "Team consistency:\n",
      "  Total unique teams: 34\n",
      "  Teams that played home: 34\n",
      "  Teams that played away: 34\n",
      "✓ All teams played both home and away\n"
     ]
    }
   ],
   "source": [
    "# Final validation checks\n",
    "print(\"FINAL VALIDATION:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 1. Check for any remaining missing values\n",
    "missing_final = pl_merged.isnull().sum()\n",
    "missing_total = missing_final.sum()\n",
    "if missing_total > 0:\n",
    "    print(f\"⚠ Warning: {missing_total} missing values remain\")\n",
    "    print(missing_final[missing_final > 0])\n",
    "else:\n",
    "    print(\"✓ No missing values in final dataset\")\n",
    "\n",
    "# 2. Check for duplicate matches\n",
    "duplicates = pl_merged.duplicated(subset=['Date', 'HomeTeam', 'AwayTeam']).sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"⚠ Warning: {duplicates} duplicate matches found\")\n",
    "else:\n",
    "    print(\"✓ No duplicate matches\")\n",
    "\n",
    "# 3. Validate date ranges for each season\n",
    "print(\"\\nDate range validation:\")\n",
    "for season in sorted(pl_merged['Season'].unique()):\n",
    "    season_data = pl_merged[pl_merged['Season'] == season]\n",
    "    min_date = season_data['Date'].min()\n",
    "    max_date = season_data['Date'].max()\n",
    "    print(f\"  {season}: {min_date.strftime('%Y-%m-%d')} to {max_date.strftime('%Y-%m-%d')} ({len(season_data)} matches)\")\n",
    "\n",
    "# 4. Check team consistency\n",
    "all_home_teams = set(pl_merged['HomeTeam'].unique())\n",
    "all_away_teams = set(pl_merged['AwayTeam'].unique())\n",
    "all_teams = all_home_teams.union(all_away_teams)\n",
    "print(f\"\\nTeam consistency:\")\n",
    "print(f\"  Total unique teams: {len(all_teams)}\")\n",
    "print(f\"  Teams that played home: {len(all_home_teams)}\")\n",
    "print(f\"  Teams that played away: {len(all_away_teams)}\")\n",
    "\n",
    "if all_home_teams == all_away_teams:\n",
    "    print(\"✓ All teams played both home and away\")\n",
    "else:\n",
    "    home_only = all_home_teams - all_away_teams\n",
    "    away_only = all_away_teams - all_home_teams\n",
    "    if home_only:\n",
    "        print(f\"⚠ Teams that only played home: {home_only}\")\n",
    "    if away_only:\n",
    "        print(f\"⚠ Teams that only played away: {away_only}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f5fa662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding calculated columns...\n",
      "  ✓ Shot accuracy calculated\n",
      "  ✓ Additional columns added\n",
      "Final dataset shape: (3800, 50)\n",
      "New columns added: ['TotalGoals', 'GoalDifference_Home', 'HomePoints', 'AwayPoints', 'MatchWeek', 'DayOfWeek', 'Month', 'Year']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>TotalGoals</th>\n",
       "      <th>HomePoints</th>\n",
       "      <th>AwayPoints</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Swansea City</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Watford</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Leicester City</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>H</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-08</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date           HomeTeam      AwayTeam FTR  TotalGoals  HomePoints  \\\n",
       "0 2015-08-08        Bournemouth   Aston Villa   A           1           0   \n",
       "1 2015-08-08            Chelsea  Swansea City   D           4           1   \n",
       "2 2015-08-08            Everton       Watford   D           4           1   \n",
       "3 2015-08-08     Leicester City    Sunderland   H           6           3   \n",
       "4 2015-08-08  Manchester United     Tottenham   H           1           3   \n",
       "\n",
       "   AwayPoints     Season  \n",
       "0           3  2015-2016  \n",
       "1           1  2015-2016  \n",
       "2           1  2015-2016  \n",
       "3           0  2015-2016  \n",
       "4           0  2015-2016  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add useful calculated columns\n",
    "print(\"Adding calculated columns...\")\n",
    "\n",
    "# Sort by date for proper calculation\n",
    "pl_merged = pl_merged.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Calculate additional match statistics\n",
    "pl_merged['TotalGoals'] = pl_merged['FTHG'] + pl_merged['FTAG']\n",
    "pl_merged['GoalDifference_Home'] = pl_merged['FTHG'] - pl_merged['FTAG']\n",
    "pl_merged['GoalDifference_Away'] = pl_merged['FTAG'] - pl_merged['FTHG']\n",
    "\n",
    "# Calculate points\n",
    "pl_merged['HomePoints'] = pl_merged['FTR'].map({'H': 3, 'D': 1, 'A': 0})\n",
    "pl_merged['AwayPoints'] = pl_merged['FTR'].map({'H': 0, 'D': 1, 'A': 3})\n",
    "\n",
    "# Calculate shot accuracy (if shot data available)\n",
    "if 'HS' in pl_merged.columns and 'HST' in pl_merged.columns:\n",
    "    pl_merged['HomeShotAccuracy'] = np.where(pl_merged['HS'] > 0, pl_merged['HST'] / pl_merged['HS'], 0)\n",
    "    pl_merged['AwayShotAccuracy'] = np.where(pl_merged['AS'] > 0, pl_merged['AST'] / pl_merged['AS'], 0)\n",
    "    print(\"  ✓ Shot accuracy calculated\")\n",
    "\n",
    "# Add match week (approximate - based on date order within season)\n",
    "pl_merged['MatchWeek'] = pl_merged.groupby('Season').cumcount() // 10 + 1\n",
    "\n",
    "# Add day of week and month\n",
    "pl_merged['DayOfWeek'] = pl_merged['Date'].dt.day_name()\n",
    "pl_merged['Month'] = pl_merged['Date'].dt.month\n",
    "pl_merged['Year'] = pl_merged['Date'].dt.year\n",
    "\n",
    "print(\"  ✓ Additional columns added\")\n",
    "print(f\"Final dataset shape: {pl_merged.shape}\")\n",
    "\n",
    "# Display summary of new columns\n",
    "new_columns = ['TotalGoals', 'GoalDifference_Home', 'HomePoints', 'AwayPoints', 'MatchWeek', 'DayOfWeek', 'Month', 'Year']\n",
    "existing_new_columns = [col for col in new_columns if col in pl_merged.columns]\n",
    "print(f\"New columns added: {existing_new_columns}\")\n",
    "\n",
    "pl_merged[['Date', 'HomeTeam', 'AwayTeam', 'FTR', 'TotalGoals', 'HomePoints', 'AwayPoints', 'Season']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da9003",
   "metadata": {},
   "source": [
    "## 6. Export to Processed Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4f217ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting cleaned dataset...\n",
      "Output file: ..\\data\\processed\\PL_matches_10years_cleaned.csv\n",
      "✓ Export successful!\n",
      "  File size: 0.82 MB\n",
      "  Verification: 3800 rows, 50 columns\n",
      "✓ Verification passed - file integrity confirmed\n",
      "\n",
      "============================================================\n",
      "DATA PROCESSING COMPLETE!\n",
      "============================================================\n",
      "Final dataset: PL_matches_10years_cleaned.csv\n",
      "Location: ..\\data\\processed\n",
      "Shape: (3800, 50)\n",
      "Date range: 2015-08-08 to 2025-05-25\n",
      "Seasons covered: 10\n",
      "Total matches: 3800\n",
      "Unique teams: 34\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned and merged dataset\n",
    "output_filename = \"PL_matches_10years_cleaned.csv\"\n",
    "output_path = PROCESSED_DATA_PATH / output_filename\n",
    "\n",
    "print(\"Exporting cleaned dataset...\")\n",
    "print(f\"Output file: {output_path}\")\n",
    "\n",
    "# Export to CSV\n",
    "pl_merged.to_csv(output_path, index=False)\n",
    "\n",
    "# Verify the export\n",
    "if os.path.exists(output_path):\n",
    "    file_size = os.path.getsize(output_path) / (1024 * 1024)  # Size in MB\n",
    "    print(f\"✓ Export successful!\")\n",
    "    print(f\"  File size: {file_size:.2f} MB\")\n",
    "    \n",
    "    # Quick verification - reload and check\n",
    "    verification_df = pd.read_csv(output_path)\n",
    "    print(f\"  Verification: {verification_df.shape[0]} rows, {verification_df.shape[1]} columns\")\n",
    "    \n",
    "    if verification_df.shape == pl_merged.shape:\n",
    "        print(\"✓ Verification passed - file integrity confirmed\")\n",
    "    else:\n",
    "        print(\"⚠ Verification failed - shape mismatch\")\n",
    "else:\n",
    "    print(\"✗ Export failed!\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATA PROCESSING COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Final dataset: {output_filename}\")\n",
    "print(f\"Location: {PROCESSED_DATA_PATH}\")\n",
    "print(f\"Shape: {pl_merged.shape}\")\n",
    "print(f\"Date range: {pl_merged['Date'].min().strftime('%Y-%m-%d')} to {pl_merged['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Seasons covered: {len(pl_merged['Season'].unique())}\")\n",
    "print(f\"Total matches: {len(pl_merged)}\")\n",
    "print(f\"Unique teams: {len(set(pl_merged['HomeTeam'].unique()) | set(pl_merged['AwayTeam'].unique()))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834f99c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has successfully:\n",
    "\n",
    "1. **Loaded 10 individual season files** (2015-16 through 2024-25)\n",
    "2. **Performed comprehensive data quality checks** on each season\n",
    "3. **Cleaned and standardized the data** including:\n",
    "   - Date format conversion\n",
    "   - Team name standardization\n",
    "   - Missing value handling\n",
    "   - Data type corrections\n",
    "4. **Integrated all seasons** into a single comprehensive dataset\n",
    "5. **Added calculated columns** for enhanced analysis:\n",
    "   - Total goals, goal differences\n",
    "   - Points calculation\n",
    "   - Shot accuracy (where available)\n",
    "   - Match week, day of week, month, year\n",
    "6. **Exported the final cleaned dataset** to the processed directory\n",
    "\n",
    "The final dataset (`PL_matches_10years_cleaned.csv`) is ready for analysis and meets all the requirements for the DATA1002 project.\n",
    "\n",
    "### Key Features of the Cleaned Dataset:\n",
    "- **Consistent structure** across all 10 seasons\n",
    "- **Standardized team names** for proper analysis\n",
    "- **Enhanced with calculated metrics** for deeper insights\n",
    "- **Quality validated** with comprehensive checks\n",
    "- **Ready for integration** with ELO and Understat data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe968ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATA VALIDATION\n",
      "==================================================\n",
      "✓ No duplicate matches found\n",
      "\n",
      "Match result validation:\n",
      "✓ All 100 sampled matches have consistent results\n",
      "\n",
      "Final dataset statistics:\n",
      "  Total matches: 3,800\n",
      "  Seasons: 10\n",
      "  Date range: 2015-08-08 00:00:00 to 2025-05-25 00:00:00\n",
      "  Total teams: 34\n",
      "  Missing values: 705\n",
      "  File size: 0.82 MB\n",
      "\n",
      "✓ Data validation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Final comprehensive validation\n",
    "print(\"FINAL DATA VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check for duplicates based on match key (Date, HomeTeam, AwayTeam)\n",
    "duplicate_matches = pl_merged.duplicated(subset=['Date', 'HomeTeam', 'AwayTeam']).sum()\n",
    "if duplicate_matches > 0:\n",
    "    print(f\"⚠ Warning: {duplicate_matches} duplicate matches found\")\n",
    "    # Show duplicates\n",
    "    duplicates = pl_merged[pl_merged.duplicated(subset=['Date', 'HomeTeam', 'AwayTeam'], keep=False)]\n",
    "    print(\"Duplicate matches:\")\n",
    "    print(duplicates[['Date', 'HomeTeam', 'AwayTeam', 'Season']].sort_values(['Date', 'HomeTeam']))\n",
    "else:\n",
    "    print(\"✓ No duplicate matches found\")\n",
    "\n",
    "# Validate match results logic\n",
    "print(\"\\nMatch result validation:\")\n",
    "result_errors = 0\n",
    "sample_size = min(100, len(pl_merged))\n",
    "sample_matches = pl_merged.sample(sample_size, random_state=42)\n",
    "\n",
    "for _, match in sample_matches.iterrows():\n",
    "    home_goals = match['FTHG']\n",
    "    away_goals = match['FTAG']\n",
    "    result = match['FTR']\n",
    "    \n",
    "    expected_result = 'H' if home_goals > away_goals else 'A' if away_goals > home_goals else 'D'\n",
    "    if result != expected_result:\n",
    "        result_errors += 1\n",
    "\n",
    "if result_errors > 0:\n",
    "    print(f\"⚠ Warning: {result_errors}/{sample_size} matches have inconsistent results\")\n",
    "else:\n",
    "    print(f\"✓ All {sample_size} sampled matches have consistent results\")\n",
    "\n",
    "print(f\"\\nFinal dataset statistics:\")\n",
    "print(f\"  Total matches: {len(pl_merged):,}\")\n",
    "print(f\"  Seasons: {len(pl_merged['Season'].unique())}\")\n",
    "print(f\"  Date range: {pl_merged['Date'].min()} to {pl_merged['Date'].max()}\")\n",
    "print(f\"  Total teams: {len(set(pl_merged['HomeTeam'].unique()) | set(pl_merged['AwayTeam'].unique()))}\")\n",
    "print(f\"  Missing values: {pl_merged.isnull().sum().sum():,}\")\n",
    "print(f\"  File size: {output_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(\"\\n✓ Data validation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24340513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
